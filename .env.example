# =========================
# Backend (APIFree / LLM)
# =========================
# Leave empty to use rule-based fallback.
APIFREE_API_KEY=
APIFREE_BASE_URL=https://api.apifree.ai/v1
APIFREE_MODEL=deepseek-ai/deepseek-r1-0528
APIFREE_TIMEOUT_SEC=60

# =========================
# Backend (Local DUI LLM, OpenAI-compatible)
# =========================
# provider: apifree | local | disabled
DUI_LLM_PROVIDER=local
# Example for Ollama OpenAI-compatible endpoint:
DUI_LLM_BASE_URL=http://127.0.0.1:11434/v1
DUI_LLM_MODEL=qwen2.5:14b-instruct
DUI_LLM_API_KEY=
DUI_LLM_TIMEOUT_SEC=60
# Optional strict global theme consistency between surfaces:
DUI_ENFORCE_CROSS_SURFACE_THEME=0

# =========================
# Backend (CORS)
# =========================
# Comma-separated origins or * for permissive mode.
DUI_CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# =========================
# Frontend (Vite)
# =========================
# Used by frontend/src/api.ts
VITE_API_BASE=http://127.0.0.1:8000

# =========================
# dev.sh runtime overrides
# =========================
BACKEND_HOST=127.0.0.1
BACKEND_PORT=8000
FRONTEND_HOST=0.0.0.0
FRONTEND_PORT=5173
